{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 启动spark运行环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T01:31:43.452050Z",
     "start_time": "2020-07-09T01:31:40.244527Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "##下面这个语句，我有印象，好像是为了满足某些shell的什么东西吧，但是删除了依然好使\n",
    "os.environ['PYSPARK_PYTHON']='/usr/bin/python2' \n",
    "spark_home = os.getenv(\"SPARK_HOME\")\n",
    "\n",
    "#将pyspark的位置增加到python的库搜索路径\n",
    "import sys\n",
    "sys.path.insert(0,os.path.join(spark_home,\"python\"))\n",
    "\n",
    "#获取sparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "def get_spark_session(app_name = None, master = \"spark://master:7077\"):\n",
    "    spark = SparkSession.builder\\\n",
    "        .master(master) \\\n",
    "        .appName(app_name) \\\n",
    "        .config(\"ui.showConsoleProgress\",\"true\") \\\n",
    "        .config(\"spark.executor.cores\",\"3\") \\\n",
    "        .config(\"spark.executor.memory\",\"10G\") \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "\n",
    "\n",
    "import time\n",
    "now_date_str = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))\n",
    "\n",
    "\n",
    "Your_app_name = \"\"\n",
    "spark = get_spark_session(Your_app_name + now_date_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T02:16:59.403823Z",
     "start_time": "2020-07-09T02:16:56.677022Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: double (nullable = true)\n",
      " |-- _c1: double (nullable = true)\n",
      " |-- _c2: double (nullable = true)\n",
      " |-- _c3: double (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_data = spark.read.options(inferschema='true').csv(\"/VChao/mllib_test/iris.data\")\n",
    "iris_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预处理数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 为类别进行编号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T01:49:39.213534Z",
     "start_time": "2020-07-09T01:49:39.207228Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T02:18:26.631485Z",
     "start_time": "2020-07-09T02:18:23.125411Z"
    }
   },
   "outputs": [],
   "source": [
    "index_model = StringIndexer(inputCol=\"_c4\", outputCol=\"class\").fit(iris_data)\n",
    "iris_data = index_model.transform(iris_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T02:18:33.502129Z",
     "start_time": "2020-07-09T02:18:33.440169Z"
    }
   },
   "outputs": [],
   "source": [
    "iris_data = iris_data.drop(\"_c4\").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理为机器学习算法可使用的数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T02:00:39.367195Z",
     "start_time": "2020-07-09T02:00:39.358563Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "data = iris_data.rdd.map(lambda row: LabeledPoint(row[-1], Vectors.dense(row[:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 按照比例切分数据 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T02:07:55.715029Z",
     "start_time": "2020-07-09T02:07:55.707557Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "splits =[train_ratio, 1 - train_ratio]\n",
    "train_data,test_data = data.randomSplit(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选择算法并训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T02:08:03.795370Z",
     "start_time": "2020-07-09T02:08:02.412214Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import RandomForest\n",
    "rf_model =RandomForest.trainClassifier(train_data,numClasses=3,numTrees=10, \\\n",
    "                                       categoricalFeaturesInfo={},featureSubsetStrategy='auto',impurity=\"gini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T02:09:22.013591Z",
     "start_time": "2020-07-09T02:09:21.714099Z"
    }
   },
   "source": [
    "### 评估算法性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T02:21:02.616726Z",
     "start_time": "2020-07-09T02:21:02.311608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0]\n",
      " [0 8 1]\n",
      " [0 0 3]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         4\n",
      "Iris-versicolor       1.00      0.89      0.94         9\n",
      " Iris-virginica       0.75      1.00      0.86         3\n",
      "\n",
      "      micro avg       0.94      0.94      0.94        16\n",
      "      macro avg       0.92      0.96      0.93        16\n",
      "   weighted avg       0.95      0.94      0.94        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre = predictions.collect()\n",
    "\n",
    "predictions = rf_model.predict(test_data.map(lambda x:x.features))\n",
    "\n",
    "\n",
    "np_pre = np.array(pre)\n",
    "labels = test_data.map(lambda x:x.label).collect()\n",
    "np_labels = np.array(labels)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print confusion_matrix(np_labels, np_pre)\n",
    "print classification_report(np_labels, np_pre,target_names=index_model.labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
